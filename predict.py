import os
import json
import torch
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import r2_score, mean_squared_error
import matplotlib

# ä»è‡ªå®šä¹‰æ¨¡å—å¯¼å…¥ä¸€ç»´æ¨¡å‹å’Œæ•°æ®é›†ç±»
from models import Vanilla_CNN_DeepONet_1D, Modified_CNN_DeepONet_1D
from dataset import DeepONetDataset_E1_1D

# è®¾ç½®matplotlibåç«¯ä¸ºAggï¼Œé€‚é…æ— GUIç¯å¢ƒï¼ˆæœåŠ¡å™¨/å‘½ä»¤è¡Œï¼‰
matplotlib.use("Agg")


def evaluate_and_plot_1d(folder_path, plot_sample_indices=[0, 1, 2]):
    """
    ä¸€ç»´DeepONetæµ‹è¯•é›†è¯„ä¼°ä¸ç»˜å›¾å‡½æ•°ï¼š
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. åŠ è½½ä¸€ç»´E1å®éªŒçš„è®­ç»ƒæ¨¡å‹ï¼Œé¢„æµ‹1Dæ°´å¤´å€¼
    2. ç»˜åˆ¶1x2å¸ƒå±€çš„ç§‘ç ”çº§å¯¹æ¯”å›¾ï¼š
       - å­å›¾1ï¼šlnKåœº(1D) + è§‚æµ‹ç‚¹æ°´å¤´çœŸå€¼(è“è‰²)vsé¢„æµ‹å€¼(çº¢è‰²)
       - å­å›¾2ï¼šæµ‹è¯•é›†æ‰€æœ‰è§‚æµ‹ç‚¹çš„çœŸå€¼vsé¢„æµ‹å€¼æ•£ç‚¹å›¾ï¼ˆå«MSE/RÂ²ï¼‰
    3. å®Œå…¨é€‚é…train.pyè¾“å‡ºçš„config.json/norm_params.npz

    å‚æ•°ï¼š
        folder_path (str): æ¨¡å‹è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„ï¼ˆå¦‚E1_1D_Vanilla_0122_1558ï¼‰
        plot_sample_indices (list): è¦ç»˜åˆ¶çš„æµ‹è¯•é›†æ ·æœ¬ç´¢å¼•åˆ—è¡¨
    """
    # ========== 1. è®¾å¤‡é…ç½®ä¸æ–‡ä»¶æ£€æŸ¥ ==========
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    # æ£€æŸ¥å…³é”®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    config_path = os.path.join(folder_path, "config.json")
    model_path = os.path.join(folder_path, "model_best.pth")
    norm_params_path = os.path.join(folder_path, "norm_params.npz")

    for file_path in [config_path, model_path, norm_params_path]:
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"å…³é”®æ–‡ä»¶ç¼ºå¤±: {file_path}")

    # ========== 2. åŠ è½½é…ç½®ä¸å½’ä¸€åŒ–å‚æ•° ==========
    # åŠ è½½å®éªŒé…ç½®
    with open(config_path, "r") as f:
        config = json.load(f)

    exp_name = config["exp_name"]
    model_type = config["model_type"]
    p_dim = config["p_dim"]
    test_idx = config["indices"]["test"]
    h_min = config["norm"]["h_min"]
    h_max = config["norm"]["h_max"]

    # åŠ è½½å½’ä¸€åŒ–å‚æ•°ï¼ˆå¤‡ç”¨ï¼Œä¼˜å…ˆä½¿ç”¨configä¸­çš„å€¼ï¼‰
    norm_params = np.load(norm_params_path)
    print(f"åŠ è½½å½’ä¸€åŒ–å‚æ•°ï¼šq_low={norm_params['q_low']:.4f}, q_high={norm_params['q_high']:.4f}")
    print(f"æ°´å¤´å½’ä¸€åŒ–èŒƒå›´ï¼šh_min={h_min:.4f}, h_max={h_max:.4f}")

    # ========== 3. åŠ è½½æ•°æ®é›†ï¼ˆæµ‹è¯•é˜¶æ®µï¼‰ ==========
    # ä»configä¸­è¯»å–æ•°æ®è·¯å¾„
    data_path = config.get("training", {}).get(
        "data_path") or r"F:\0projects\deeponet_1d\data_1d\E1_1D_Final_Dataset_Pack_pos20.npz"

    # æµ‹è¯•é˜¶æ®µï¼šåŠ è½½é¢„å­˜çš„å½’ä¸€åŒ–å‚æ•°ï¼Œä¸é‡æ–°è®¡ç®—
    dataset = DeepONetDataset_E1_1D(
        file_path=data_path,
        quantile=0.95,
        save_norm_params=False,
        norm_params_path=norm_params_path
    )
    # æ„å»ºæµ‹è¯•é›†Subset
    test_dataset = torch.utils.data.Subset(dataset, test_idx)
    print(f"æµ‹è¯•é›†æ ·æœ¬æ•°: {len(test_dataset)}")

    # ========== 4. åŠ è½½æ¨¡å‹å¹¶è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ ==========
    if model_type == "Vanilla":
        model = Vanilla_CNN_DeepONet_1D(p=p_dim).to(device)
    else:  # Modified
        model = Modified_CNN_DeepONet_1D(p=p_dim).to(device)

    # åŠ è½½æœ€ä¼˜æ¨¡å‹æƒé‡
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()
    print(f"æˆåŠŸåŠ è½½{model_type}æ¨¡å‹ï¼Œå‚æ•°ç»´åº¦p={p_dim}")

    # ========== 5. å…¨æµ‹è¯•é›†é¢„æµ‹ä¸æŒ‡æ ‡è®¡ç®— ==========
    all_true = []
    all_pred = []

    with torch.no_grad():
        for idx in range(len(test_dataset)):
            # è·å–å•ä¸ªæ ·æœ¬æ•°æ®
            f, q, y_true = test_dataset[idx]
            f = f.unsqueeze(0).to(device)  # (1, 1, 64)
            q = q.unsqueeze(0).to(device)  # (1, M, 1)

            # Modifiedæ¨¡å‹éœ€è¦æ‹¼æ¥äº•æ©ç 
            if model_type == "Modified":
                # è·å–åŸå§‹æ ·æœ¬ID -> äº•æ©ç 
                original_idx = test_idx[idx]
                well_mask = dataset.well_mask[original_idx].unsqueeze(0).unsqueeze(0).to(device)  # (1,1,64)
                f = torch.cat([f, well_mask], dim=1)  # (1,2,64)

            # é¢„æµ‹å¹¶åå½’ä¸€åŒ–
            y_pred_norm = model(f, q)
            y_pred = dataset.inverse_normalize_head(y_pred_norm.cpu()).numpy().flatten()
            y_true = dataset.inverse_normalize_head(y_true.cpu()).numpy().flatten()

            all_true.extend(y_true)
            all_pred.extend(y_pred)

    # è®¡ç®—å…¨æµ‹è¯•é›†è¯„ä¼°æŒ‡æ ‡
    all_true = np.array(all_true)
    all_pred = np.array(all_pred)
    mse_total = mean_squared_error(all_true, all_pred)
    r2_total = r2_score(all_true, all_pred)
    print(f"\nå…¨æµ‹è¯•é›†è¯„ä¼°ç»“æœï¼š")
    print(f"MSE: {mse_total:.4e} | RÂ²: {r2_total:.4f}")

    # ========== 6. ç»˜åˆ¶æŒ‡å®šæ ·æœ¬çš„å¯è§†åŒ–å›¾ ==========
    for plot_idx in plot_sample_indices:
        if plot_idx >= len(test_dataset):
            print(f"è·³è¿‡è¶…å‡ºèŒƒå›´çš„ç´¢å¼•: {plot_idx} (æµ‹è¯•é›†ä»…{len(test_dataset)}ä¸ªæ ·æœ¬)")
            continue

        # è·å–å½“å‰æ ·æœ¬æ•°æ®
        original_sample_id = test_idx[plot_idx]
        f, q, y_true_norm = test_dataset[plot_idx]
        f = f.unsqueeze(0).to(device)
        q = q.unsqueeze(0).to(device)

        # Modifiedæ¨¡å‹æ‹¼æ¥äº•æ©ç 
        if model_type == "Modified":
            well_mask = dataset.well_mask[original_sample_id].unsqueeze(0).unsqueeze(0).to(device)
            f = torch.cat([f, well_mask], dim=1)

        # æ¨¡å‹é¢„æµ‹
        with torch.no_grad():
            y_pred_norm = model(f, q)

        # åå½’ä¸€åŒ–å¾—åˆ°çœŸå®æ°´å¤´å€¼
        y_true = dataset.inverse_normalize_head(y_true_norm).numpy()
        y_pred = dataset.inverse_normalize_head(y_pred_norm.cpu()).numpy().flatten()

        # ========== 7. 1Då¯è§†åŒ–ç»˜å›¾ ==========
        fig, axes = plt.subplots(1, 2, figsize=(16, 6))

        # å­å›¾1ï¼š1D lnKåœº + æ°´å¤´å€¼å¯¹æ¯”
        ax1 = axes[0]
        # ç»˜åˆ¶lnKåœºï¼ˆ1Dï¼Œyè½´ä¸ºlnKå€¼ï¼Œxè½´ä¸ºä½ç½®ï¼‰
        lnk_field = dataset.fields[original_sample_id].squeeze().numpy()  # (64,)
        x_pos = np.arange(64) * (1.0 / 64) + (1.0 / 64) / 2  # å½’ä¸€åŒ–åæ ‡
        ax1.plot(x_pos, lnk_field, color='gray', linewidth=2, label='lnK Field')
        ax1.fill_between(x_pos, lnk_field, alpha=0.3, color='gray')

        # ç»˜åˆ¶è§‚æµ‹ç‚¹æ°´å¤´çœŸå€¼å’Œé¢„æµ‹å€¼
        obs_coords = dataset.coords[original_sample_id].squeeze().numpy()  # (M,)
        ax1.scatter(obs_coords, y_true, color='blue', s=50, label='True Head', zorder=3)
        ax1.scatter(obs_coords, y_pred, color='red', marker='x', s=50, label='Pred Head', zorder=4)

        # æ ‡æ³¨æŠ½æ°´äº•ä½ç½®
        # well_loc = dataset.coords_raw[original_sample_id][int(dataset.well_loc_1d[original_sample_id])]
        # ax1.axvline(x=well_loc * (1.0 / 64) + (1.0 / 64) / 2, color='black', linestyle='--', label='Pumping Well')

        ax1.set_title(f"1D lnK Field & Head Values (Sample {original_sample_id})", fontsize=12)
        ax1.set_xlabel("Normalized Position", fontsize=10)
        ax1.set_ylabel("Value", fontsize=10)
        ax1.legend()
        ax1.grid(alpha=0.3)

        # å­å›¾2ï¼šå½“å‰æ ·æœ¬çœŸå€¼vsé¢„æµ‹å€¼æ•£ç‚¹å›¾ + å…¨æµ‹è¯•é›†æŒ‡æ ‡
        ax2 = axes[1]
        # å½“å‰æ ·æœ¬æ•£ç‚¹
        ax2.scatter(y_true, y_pred, color='gold', edgecolors='black', s=50, alpha=0.8,
                    label=f'Sample {original_sample_id}')
        # 1:1å‚è€ƒçº¿
        lims = [
            min(y_true.min(), y_pred.min()) - 0.1,
            max(y_true.max(), y_pred.max()) + 0.1
        ]
        ax2.plot(lims, lims, 'r--', linewidth=2, label='1:1 Line')

        # è®¡ç®—å½“å‰æ ·æœ¬æŒ‡æ ‡
        mse_sample = mean_squared_error(y_true, y_pred)
        r2_sample = r2_score(y_true, y_pred)

        # æ ‡æ³¨æŒ‡æ ‡
        ax2.text(0.05, 0.95,
                 f"Sample MSE: {mse_sample:.4e}\nSample RÂ²: {r2_sample:.4f}\nTotal Test MSE: {mse_total:.4e}\nTotal Test RÂ²: {r2_total:.4f}",
                 transform=ax2.transAxes, verticalalignment='top',
                 bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))

        ax2.set_title("True vs Predicted Head Values", fontsize=12)
        ax2.set_xlabel("True Head (m)", fontsize=10)
        ax2.set_ylabel("Predicted Head (m)", fontsize=10)
        ax2.legend()
        ax2.grid(alpha=0.3)

        # ========== 8. ä¿å­˜å›¾ç‰‡ ==========
        plt.tight_layout()
        save_path = os.path.join(folder_path, f"1D_test_sample_{plot_idx}_id_{original_sample_id}.png")
        plt.savefig(save_path, dpi=300)
        plt.close()
        print(f"âœ… æ ·æœ¬{plot_idx}å¯è§†åŒ–å›¾å·²ä¿å­˜: {save_path}")

    # ========== 9. ä¿å­˜å…¨æµ‹è¯•é›†è¯„ä¼°ç»“æœ ==========
    eval_result = {
        "total_test_samples": len(test_dataset),
        "total_observation_points": len(all_true),
        "mse": float(mse_total),
        "r2": float(r2_total),
        "h_min": float(h_min),
        "h_max": float(h_max),
        "model_type": model_type,
        "p_dim": p_dim
    }
    with open(os.path.join(folder_path, "test_evaluation.json"), "w") as f:
        json.dump(eval_result, f, indent=4)
    print(f"\nğŸ“Š å…¨æµ‹è¯•é›†è¯„ä¼°ç»“æœå·²ä¿å­˜è‡³: {os.path.join(folder_path, 'test_evaluation.json')}")


if __name__ == "__main__":
    # æ›¿æ¢ä¸ºä½ çš„æ¨¡å‹è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„
    TARGET_DIR = r"F:\0projects\deeponet_1d\outputs_1D\E1_1D_Vanilla_0122_1658"
    # ç»˜åˆ¶æµ‹è¯•é›†å‰3ä¸ªæ ·æœ¬
    evaluate_and_plot_1d(TARGET_DIR, plot_sample_indices=[0, 1, 2])